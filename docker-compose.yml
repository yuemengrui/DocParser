services:
  layout_server_doclayoutyolo:
    container_name: layout_server_doclayoutyolo
    image: registry.cn-beijing.aliyuncs.com/yuemengrui/ai:pytorch2.1.2-cuda12.1-cudnn8-ubuntu20.04-py311-0.2
    command: [ "/bin/bash", "-c", "/workspace/Layout_Analysis/docker_run.sh" ]
    volumes:
      - ./Layout_Analysis:/workspace/Layout_Analysis  # 挂载服务源码
      - ./Layout_Analysis/configs/model_layout_yolo.json:/workspace/model_config.json  # 挂载配置文件
      - ./Models/Layout/doclayout_yolo.pt:/workspace/models/doclayout_yolo.pt  # 挂载与配置文件对应的模型
    ports:
      - "24680:24680"
    restart: unless-stopped
    networks:
      - ainet
    stdin_open: true
    tty: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:24680/ai/health" ]
      interval: 60s
      start_period: 60s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]

  layout_server_yolov10l:
    container_name: layout_server_yolov10l
    image: registry.cn-beijing.aliyuncs.com/yuemengrui/ai:pytorch2.1.2-cuda12.1-cudnn8-ubuntu20.04-py311-0.2
    command: [ "/bin/bash", "-c", "/workspace/Layout_Analysis/docker_run.sh" ]
    volumes:
      - ./Layout_Analysis:/workspace/Layout_Analysis
      - ./Layout_Analysis/configs/model_yolov10l.json:/workspace/model_config.json
      - ./Models/Layout/yolov10l.pt:/workspace/models/yolov10l.pt
    ports:
      - "24681:24680"
    restart: unless-stopped
    networks:
      - ainet
    stdin_open: true
    tty: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:24680/ai/health" ]
      interval: 60s
      start_period: 60s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]

  layout_server_yolom960:
    container_name: layout_server_yolom960
    image: registry.cn-beijing.aliyuncs.com/yuemengrui/ai:pytorch2.1.2-cuda12.1-cudnn8-ubuntu20.04-py311-0.2
    command: [ "/bin/bash", "-c", "/workspace/Layout_Analysis/docker_run.sh" ]
    volumes:
      - ./Layout_Analysis:/workspace/Layout_Analysis
      - ./Layout_Analysis/configs/model_yolom_960.json:/workspace/model_config.json
      - ./Models/Layout/layout_m_960.pt:/workspace/models/layout_m_960.pt
    ports:
      - "24682:24680"
    restart: unless-stopped
    networks:
      - ainet
    stdin_open: true
    tty: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:24680/ai/health" ]
      interval: 60s
      start_period: 60s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]


  table_server_internvl2_1b:
    container_name: table_server_internvl2_1b
    image: registry.cn-beijing.aliyuncs.com/yuemengrui/ai:pytorch2.1.2-cuda12.1-cudnn8-ubuntu20.04-py311-0.2
    command: [ "/bin/bash", "-c", "/workspace/Table_Parser/docker_run.sh" ]
    volumes:
      - ./Table_Parser:/workspace/Table_Parser
      - ./Table_Parser/configs/structtable-internvl2-1b.json:/workspace/model_config.json
      - ./Models/Table/StructTable-InternVL2-1B:/workspace/models/StructTable-InternVL2-1B
    ports:
      - "24683:24680"
    restart: unless-stopped
    networks:
      - ainet
    stdin_open: true
    tty: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:24680/ai/health" ]
      interval: 60s
      start_period: 60s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]

  formula_server:
    container_name: formula_server
    image: registry.cn-beijing.aliyuncs.com/yuemengrui/ai:pytorch2.1.2-cuda12.1-cudnn8-ubuntu20.04-py311-0.2
    command: [ "/bin/bash", "-c", "/workspace/Formula_Server/docker_run.sh" ]
    volumes:
      - ./Formula_Server:/workspace/Formula_Server
      - ./Formula_Server/configs/formula_config.json:/workspace/model_config.json
      - ./Models/Formula/det/formula_det_yolo.pt:/workspace/models/formula_det_yolo.pt
      - ./Models/Formula/rec/unimernet_base:/workspace/models/unimernet
    ports:
      - "24684:24680"
    restart: unless-stopped
    networks:
      - ainet
    stdin_open: true
    tty: true
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:24680/ai/health" ]
      interval: 60s
      start_period: 60s
      timeout: 10s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]


networks:
  ainet:
    driver: bridge
    name: ainet
    external: false
